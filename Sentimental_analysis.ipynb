{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xBds-ChTJ0nzgODEBEusCWNM2SEgtieA",
      "authorship_tag": "ABX9TyOTpNvaYi9TUw5TFsA+LTBJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RwIOs1fhqF0",
        "outputId": "0e9211d0-97a6-42ba-a625-52cafeba06a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUjo8r6fhHP0"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Load dataset\n",
        "try:\n",
        "    data = pd.read_csv('/content/Amazon_Unlocked_Mobile.csv', low_memory=False)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n",
        "\n",
        "# Drop missing values\n",
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data cleaning"
      ],
      "metadata": {
        "id": "zoJuvXzjsKzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Define your cleanText function\n",
        "def cleanText(raw_text, remove_stopwords=False, stemming=False, split_text=False):\n",
        "    '''\n",
        "    Convert a raw review to a cleaned review\n",
        "    '''\n",
        "    # Remove HTML\n",
        "    text = BeautifulSoup(raw_text, 'lxml').get_text()\n",
        "\n",
        "    # Remove non-alphabet characters\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "\n",
        "    # Convert to lower case and split into words\n",
        "    words = letters_only.lower().split()\n",
        "\n",
        "    # Optionally remove stopwords\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if w not in stops]\n",
        "\n",
        "    # Optionally perform stemming\n",
        "    if stemming:\n",
        "        stemmer = SnowballStemmer('english')\n",
        "        words = [stemmer.stem(w) for w in words]\n",
        "\n",
        "    # Return list of words or joined text\n",
        "    if split_text:\n",
        "        return words\n",
        "\n",
        "    return \" \".join(words)"
      ],
      "metadata": {
        "id": "uHFYFGZDo9cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_reviews'] = data['Reviews'].apply(lambda x: cleanText(x, remove_stopwords=True, stemming=True))\n",
        "\n",
        "# Feature Extraction using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf.fit_transform(data['clean_reviews'])\n",
        "\n",
        "# Sentiment Labeling (Assuming reviews with Rating > 3 are positive)\n",
        "data['sentiment'] = data['Rating'].apply(lambda x: 1 if x > 3 else 0)\n",
        "y = data['sentiment']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Training (Logistic Regression)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FviiJbwVpGpS",
        "outputId": "cc8af78c-32a0-405d-ea69-1f335e63cfe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-259a154b8231>:13: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(raw_text, 'lxml').get_text()\n",
            "<ipython-input-17-259a154b8231>:13: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  text = BeautifulSoup(raw_text, 'lxml').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8978404570334699\n",
            "Confusion Matrix: [[16706  4129]\n",
            " [ 2702 43329]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Function for User Input\n",
        "def predict_review(text):\n",
        "    # Clean the input text using your custom cleanText function\n",
        "    clean_input = cleanText(text, remove_stopwords=True, stemming=True)\n",
        "\n",
        "    # Vectorize the cleaned input text using the pre-fitted TF-IDF vectorizer\n",
        "    vectorized_input = tfidf.transform([clean_input])\n",
        "\n",
        "    # Make the prediction using the trained model\n",
        "    prediction = model.predict(vectorized_input)\n",
        "\n",
        "    # Return the result as 'Positive' or 'Negative'\n",
        "    return 'Positive' if prediction == 1 else 'Negative'\n",
        "\n",
        "# Example\n",
        "print(predict_review(\"Worst Phone ever. Not worth it\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COb7mZanhKHP",
        "outputId": "0906e9de-e4a1-4523-c96c-ed70b6ee47e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Testing"
      ],
      "metadata": {
        "id": "p54dP6ScqDVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Postive Reviews"
      ],
      "metadata": {
        "id": "p_mddjbJqHR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_review(\"I love this phone! The battery life is amazing, and the screen is super clear.\"))\n",
        "print(predict_review(\"Great camera quality and fast performance. Highly recommended!\"))\n",
        "print(predict_review(\"Best phone I've ever owned. Everything works perfectly and it feels premium.\"))\n",
        "print(predict_review(\"The display is vibrant, and the speakers sound great. Definitely worth the price.\"))\n",
        "print(predict_review(\"Excellent phone for the price, no complaints about its performance.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h_xEbcsp-_F",
        "outputId": "0b5a1a91-1aad-4efa-a9cd-305ca5992354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n",
            "Positive\n",
            "Positive\n",
            "Positive\n",
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Negative Reviews"
      ],
      "metadata": {
        "id": "3sWfEzg_qnyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_review(\"Terrible battery life, and it keeps freezing. Not worth the money.\"))\n",
        "print(predict_review(\"The phone overheats quickly and the camera quality is very poor.\"))\n",
        "print(predict_review(\"I'm really disappointed. The phone lags constantly, and the display is not great.\"))\n",
        "print(predict_review(\"I had high expectations, but it crashes frequently and the battery drains fast.\"))\n",
        "print(predict_review(\"Not happy with this purchase. The phone feels cheap and slow.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiREHYwkqrSH",
        "outputId": "4fde13aa-591e-4056-90bd-041ed71802ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n",
            "Negative\n",
            "Negative\n",
            "Negative\n",
            "Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mixed Reviews"
      ],
      "metadata": {
        "id": "kv477fIVrGdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_review(\"The phone is okay, but the battery life could be better.\"))\n",
        "print(predict_review(\"It's a decent phone for the price, but the camera isn't the best.\"))\n",
        "print(predict_review(\"The screen is nice, but the phone gets hot sometimes.\"))\n",
        "print(predict_review(\"The phone is fast, but the design is a little boring.\"))\n",
        "print(predict_review(\"I like the phone overall, but the software is a bit buggy.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adGuR4SUrJWk",
        "outputId": "0150d28e-771c-4837-d3dd-c191ce534b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n",
            "Positive\n",
            "Negative\n",
            "Positive\n",
            "Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "Ymc54wOIrpWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, '/content/drive/MyDrive/Mini Project Model Sem 7/sentiment_model_400k.pkl')\n",
        "\n",
        "# Save the TF-IDF vectorizer\n",
        "joblib.dump(tfidf, '/content/drive/MyDrive/Mini Project Model Sem 7/tfidf_vectorizer_400k.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOBek6vrrrsn",
        "outputId": "2b5f6f63-af9e-463c-e8a2-62d1938ff61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Mini Project Model Sem 7/tfidf_vectorizer_400k.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}